{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f0cafc0-1993-411c-9247-d75ac091280b",
   "metadata": {},
   "source": [
    "# Performance Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67ce4a31-1781-4f46-a7ce-e2b1f6cedc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost     : 1.5.1\n",
      "pandas      : 1.3.4\n",
      "numpy       : 1.21.3\n",
      "scikit-learn: 0.0\n",
      "\n",
      "Python 3.8.12\n"
     ]
    }
   ],
   "source": [
    "import watermark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "import datetime\n",
    "import random\n",
    "import copy\n",
    "import os\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "import ray\n",
    "from tqdm import tqdm\n",
    "\n",
    "%reload_ext watermark\n",
    "%watermark -p xgboost,pandas,numpy,scikit-learn\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381c55c2-1ec2-43fc-8c66-4a2acbc4b857",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf2e92fa-1bf4-4435-a1f3-4e9613ec83d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        userId  movieId  rating   timestamp\n",
      "0            1        1     4.0   964982703\n",
      "1            1        3     4.0   964981247\n",
      "2            1        6     4.0   964982224\n",
      "3            1       47     5.0   964983815\n",
      "4            1       50     5.0   964982931\n",
      "...        ...      ...     ...         ...\n",
      "100831     610   166534     4.0  1493848402\n",
      "100832     610   168248     5.0  1493850091\n",
      "100833     610   168250     5.0  1494273047\n",
      "100834     610   168252     5.0  1493846352\n",
      "100835     610   170875     3.0  1493846415\n",
      "\n",
      "[100836 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read ratings df\n",
    "path = \"data_small\"\n",
    "use_large = False\n",
    "if (use_large):\n",
    "    path = \"data_large\"\n",
    "    ratings = pd.read_csv('./' + path + '/ratings.csv')[:1000000]\n",
    "else:\n",
    "    ratings = pd.read_csv('./' + path + '/ratings.csv')\n",
    "\n",
    "movies = pd.read_csv('./' + path + '/movies.csv')\n",
    "\n",
    "print(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fefb6be-d101-4bac-ab62-fe647d42e9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9737</th>\n",
       "      <td>193581</td>\n",
       "      <td>Black Butler: Book of the Atlantic (2017)</td>\n",
       "      <td>Action|Animation|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9738</th>\n",
       "      <td>193583</td>\n",
       "      <td>No Game No Life: Zero (2017)</td>\n",
       "      <td>Animation|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9739</th>\n",
       "      <td>193585</td>\n",
       "      <td>Flint (2017)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9740</th>\n",
       "      <td>193587</td>\n",
       "      <td>Bungo Stray Dogs: Dead Apple (2018)</td>\n",
       "      <td>Action|Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9741</th>\n",
       "      <td>193609</td>\n",
       "      <td>Andrew Dice Clay: Dice Rules (1991)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9742 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieId                                      title  \\\n",
       "0           1                           Toy Story (1995)   \n",
       "1           2                             Jumanji (1995)   \n",
       "2           3                    Grumpier Old Men (1995)   \n",
       "3           4                   Waiting to Exhale (1995)   \n",
       "4           5         Father of the Bride Part II (1995)   \n",
       "...       ...                                        ...   \n",
       "9737   193581  Black Butler: Book of the Atlantic (2017)   \n",
       "9738   193583               No Game No Life: Zero (2017)   \n",
       "9739   193585                               Flint (2017)   \n",
       "9740   193587        Bungo Stray Dogs: Dead Apple (2018)   \n",
       "9741   193609        Andrew Dice Clay: Dice Rules (1991)   \n",
       "\n",
       "                                           genres  \n",
       "0     Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                      Adventure|Children|Fantasy  \n",
       "2                                  Comedy|Romance  \n",
       "3                            Comedy|Drama|Romance  \n",
       "4                                          Comedy  \n",
       "...                                           ...  \n",
       "9737              Action|Animation|Comedy|Fantasy  \n",
       "9738                     Animation|Comedy|Fantasy  \n",
       "9739                                        Drama  \n",
       "9740                             Action|Animation  \n",
       "9741                                       Comedy  \n",
       "\n",
       "[9742 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c39be7f4-5f67-4d6f-b5f2-0470eb9ee31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9742/9742 [00:00<00:00, 1177344.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(no genres listed)', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'IMAX', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "genres_set = set()\n",
    "for string in tqdm(movies.genres):\n",
    "    genres_set.update(string.split('|'))\n",
    "#genres.remove('(no genres listed)')\n",
    "genres = sorted(genres_set)\n",
    "print(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62c88906-630e-4cc3-869d-984598f09887",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9742/9742 [00:20<00:00, 471.77it/s]\n"
     ]
    }
   ],
   "source": [
    "for genre in genres:\n",
    "    ratings[genre] = False\n",
    "\n",
    "for movie in tqdm(movies.movieId):\n",
    "    for genre in movies.genres[movies.loc[movies.movieId == movie].index[0]].split('|'):\n",
    "        ratings.loc[ratings.movieId == movie, [genre]] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37c3f66e-fe47-41bf-b960-2cdda6884d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100836, 24)\n",
      "(62518, 24)\n"
     ]
    }
   ],
   "source": [
    "# Delete movies with fewer than 25 ratings\n",
    "data = ratings.pivot(index = \"userId\", columns = \"movieId\", values = \"rating\")\n",
    "print(ratings.shape)\n",
    "to_del = list()\n",
    "counts = data.count(axis = 0, numeric_only = True)\n",
    "for i in data.columns.values:\n",
    "    if (counts[i] < 25):\n",
    "        to_del.append(i)\n",
    "ratings = ratings[~(ratings.movieId.isin(to_del))]\n",
    "print(ratings.shape)\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bd828e7-58b2-4e9e-83ce-19d2e8c7a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def insufficient_ratings(dataset, user):\n",
    "    user_ratings = sum(dataset.userId == user)\n",
    "    if (user_ratings < 20):\n",
    "        return user\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7222a454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 610/610 [00:01<00:00, 556.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(insufficient_ratings pid=19416)\u001b[0m \n",
      "There were 61 users with fewer than 20 ratings. They have been removed from the dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Removes users who no longer have 20 ratings\n",
    "\n",
    "def to_iterator(obj_ids):\n",
    "    while obj_ids:\n",
    "        done, obj_ids = ray.wait(obj_ids)\n",
    "        yield ray.get(done[0])\n",
    "\n",
    "dat = ray.put(ratings)\n",
    "obj_ids = [insufficient_ratings.remote(dat, user) for user in ratings.userId.unique()]\n",
    "results = []\n",
    "for x in tqdm(to_iterator(obj_ids), total = len(obj_ids)):\n",
    "    if x > -1:\n",
    "        results.append(x)\n",
    "\n",
    "ratings = ratings.loc[~(ratings.userId.isin(results))]\n",
    "\n",
    "del dat\n",
    "        \n",
    "print(\"There were\", len(results), \"users with fewer than 20 ratings. They have been removed from the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27ad3e85-a683-40e8-b334-8e1da4936a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Valid/Test sizes: 38700 10195 12724\n"
     ]
    }
   ],
   "source": [
    "# Note that GroupShuffleSplit allows us to have distinct users in the training, validation, and test sets\n",
    "\n",
    "# Split into 80-20 training - testing split\n",
    "train_inds, test_inds = next(GroupShuffleSplit(test_size=.20, n_splits=2, random_state = 42).split(ratings, groups=ratings.userId))\n",
    "\n",
    "train_val = ratings.iloc[train_inds].copy()\n",
    "test = ratings.iloc[test_inds].copy()\n",
    "\n",
    "# Split into 80-20 training - validation split\n",
    "train_inds, val_inds = next(GroupShuffleSplit(test_size=.20, n_splits=2, random_state = 42).split(train_val, groups=train_val.userId))\n",
    "\n",
    "training = train_val.iloc[train_inds].copy()\n",
    "validation = train_val.iloc[val_inds].copy()\n",
    "\n",
    "print('Train/Valid/Test sizes:', training.shape[0], validation.shape[0], test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec799c23-52a6-404f-927a-96b54d7964bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As it is, this will take the 10 most recent ratings for a user to use for prediction\n",
    "# Commented out sections allow random ratings to be taken\n",
    "\n",
    "@ray.remote\n",
    "def prepare_helper(user, dataset):\n",
    "    #random.seed(1)\n",
    "    user_ratings = dataset.loc[dataset.userId == user]\n",
    "                               \n",
    "    # Randomly select 10 movies to remove\n",
    "    #selected_movies = random.sample(range(0, user_ratings.shape[0]), 10)\n",
    "    #selected_movies = random.choices(list(user_ratings.movieId), k=10)\n",
    "                               \n",
    "    # This will select the 10 most recent ratings for this user\n",
    "    selected_movies = user_ratings.sort_values(by = \"timestamp\", ascending = False).movieId.values[0:10]\n",
    "    \n",
    "    # Add the removed movies to the removed dataframe\n",
    "    removed_movies = user_ratings[user_ratings.movieId.isin(selected_movies)]\n",
    "    \n",
    "    return removed_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dd65052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes in either the validation or training set\n",
    "# Removes the most recent 10 ratings for each user, and returns them as removed_movies\n",
    "# Returns the original dataset with the ratings to predict removed as new_movies\n",
    "def prepare_data(dataset):\n",
    "    # For validation and test data, remove 10 rated movies to be predicted\n",
    "    removed_movies = pd.DataFrame(columns = dataset.columns)\n",
    "    # Iterate over each user\n",
    "    \n",
    "    def to_iterator(obj_ids):\n",
    "        while obj_ids:\n",
    "            done, obj_ids = ray.wait(obj_ids)\n",
    "            yield ray.get(done[0])\n",
    "    dat = ray.put(dataset)\n",
    "    obj_ids = [prepare_helper.remote(user, dat) for user in dataset[\"userId\"].unique()]\n",
    "    results = []\n",
    "    for x in tqdm(to_iterator(obj_ids), total = len(obj_ids)):\n",
    "        results.append(x)\n",
    "    \n",
    "    # Combine removed movies:\n",
    "    for result in tqdm(results):\n",
    "        removed_movies = pd.concat([removed_movies, result])\n",
    "        \n",
    "    # Remove all of the user-movie combinations in removed_moviews from dataset\n",
    "    new_movies = pd.merge(dataset, removed_movies, indicator=True, how='outer').query('_merge==\"left_only\"').drop('_merge', axis=1)\n",
    "    del dat\n",
    "    \n",
    "    return removed_movies, new_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e73b9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 09:51:36,213\tINFO worker.py:832 -- Calling ray.init() again after it has already been called.\n",
      "100%|██████████| 88/88 [00:00<00:00, 1491.97it/s]\n",
      "100%|██████████| 88/88 [00:00<00:00, 1006.52it/s]\n",
      "2021-12-01 09:51:36,536\tINFO worker.py:832 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time building validation set: 0:00:00.268082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:00<00:00, 1992.11it/s]\n",
      "100%|██████████| 110/110 [00:00<00:00, 874.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time building test set: 0:00:00.346785\n"
     ]
    }
   ],
   "source": [
    "# Get the proper splits for the validation and testing sets\n",
    "if (os.path.isfile('./' + path + '/validation_removed_tmp.csv') and os.path.isfile('./' + path + '/validation_new.csv')):\n",
    "    print(\"Validation set already exists\" )\n",
    "    validation_removed = pd.read_csv('./' + path + '/validation_removed_tmp.csv')\n",
    "    validation_new = pd.read_csv('./' + path + '/validation_new.csv')\n",
    "else:\n",
    "    start = datetime.datetime.now()\n",
    "    ray.init(ignore_reinit_error=True)\n",
    "    validation_removed, validation_new = prepare_data(validation)\n",
    "    print('Time building validation set: {}'.format(datetime.datetime.now()-start))\n",
    "    validation_removed.to_csv('./' + path + '/validation_removed_tmp.csv')\n",
    "    validation_new.to_csv('./' + path + '/validation_new.csv')\n",
    "\n",
    "if (os.path.isfile('./' + path + '/test_removed_tmp.csv') and os.path.isfile('./' + path + '/test_new.csv')):\n",
    "    print(\"Test set already exists\" )\n",
    "    test_removed = pd.read_csv('./' + path + '/test_removed_tmp.csv')\n",
    "    test_new = pd.read_csv('./' + path + '/test_new.csv')                                                                \n",
    "else:\n",
    "    start = datetime.datetime.now()\n",
    "    ray.init(ignore_reinit_error=True)\n",
    "    test_removed, test_new = prepare_data(test)\n",
    "    print('Time building test set: {}'.format(datetime.datetime.now()-start))\n",
    "    test_removed.to_csv('./' + path + '/test_removed_tmp.csv')\n",
    "    test_new.to_csv('./' + path + '/test_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5385e4b2-01f5-4f9d-baa9-f5e540b21c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return tuple of (user, average rating for user)\n",
    "@ray.remote\n",
    "def add_user(dataset, user):\n",
    "    return (user, np.mean(dataset[dataset[\"userId\"] == user][\"rating\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca37d3e9-b046-4f58-956f-e997561c41a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns dataset with the average user rating for each user\n",
    "# Optionally takes in removed when using validation or test data\n",
    "def user_avg(dataset, using_removed = False, removed = pd.DataFrame()):\n",
    "    def to_iterator(obj_ids):\n",
    "        while obj_ids:\n",
    "            done, obj_ids = ray.wait(obj_ids)\n",
    "            yield ray.get(done[0])\n",
    "\n",
    "    # Get the user averages\n",
    "    dataset[\"userAvg\"] = 0.0\n",
    "    dat = ray.put(dataset)\n",
    "    obj_ids = ([add_user.remote(dat, user) for user in dataset.userId.unique()])\n",
    "    results = []\n",
    "    for x in tqdm(to_iterator(obj_ids), total = len(obj_ids)):\n",
    "        results.append(x)\n",
    "    del dat\n",
    "\n",
    "    if (using_removed):\n",
    "        removed[\"userAvg\"] = 0.0\n",
    "    print(\"Combining data\")\n",
    "    for result in tqdm(results):\n",
    "        dataset.loc[dataset[\"userId\"] == result[0], [\"userAvg\"]] = result[1]\n",
    "        if (using_removed):\n",
    "            removed.loc[removed.userId == result[0], [\"userAvg\"]] = result[1]\n",
    "    \n",
    "    return dataset, removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02ddf8db-9e02-407a-8dba-338d34eec657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return tuple of (movie, average rating for movie)\n",
    "@ray.remote\n",
    "def add_movie(dataset, movie):\n",
    "    return (movie, np.mean(dataset[dataset[\"movieId\"] == movie][\"rating\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12240444-0490-44ad-87df-7b93afc2ac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns dataset with the average movie rating for each movie\n",
    "def movie_avg(dataset, removed):\n",
    "    def to_iterator(obj_ids):\n",
    "        while obj_ids:\n",
    "            done, obj_ids = ray.wait(obj_ids)\n",
    "            yield ray.get(done[0])\n",
    "\n",
    "    # Get the movie averages\n",
    "    dataset[\"movieAvg\"] = 0.0\n",
    "    dat = ray.put(dataset)\n",
    "    obj_ids = ([add_movie.remote(dat, movie) for movie in dataset.movieId.unique()])\n",
    "    results = []\n",
    "    for x in tqdm(to_iterator(obj_ids), total = len(obj_ids)):\n",
    "        results.append(x)\n",
    "    del dat\n",
    "    \n",
    "    removed[\"movieAvg\"] = 0.0\n",
    "    print(\"Combining data\")\n",
    "    for result in tqdm(results):\n",
    "        dataset.loc[dataset[\"movieId\"] == result[0], [\"movieAvg\"]] = result[1]\n",
    "        removed.loc[removed.movieId == result[0], [\"movieAvg\"]] = result[1]\n",
    "        \n",
    "    return dataset, removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f67d751-3753-4522-b63c-b22a7e550785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return datasets with average movie rating and average user rating for each row\n",
    "def add_avgs(training, validation_new, test_new, validation_removed, test_removed):\n",
    "    print(\"\\nCalculating training set user averages\")\n",
    "    training, dummy = user_avg(training, False)\n",
    "    print(\"\\nCalculating validation set user averages\")\n",
    "    validation_new, validation_removed = user_avg(validation_new, True, validation_removed)\n",
    "    print(\"\\nCalculating test set user averages\")\n",
    "    test_new, test_removed = user_avg(test_new, True, test_removed)\n",
    "    \n",
    "    print(\"\\nCalculating validation set movie averages\")\n",
    "    training_validation, validation_removed = movie_avg(pd.concat([training, validation_new]), validation_removed)\n",
    "    \n",
    "    print(\"\\nCalculating test set movie averages\")\n",
    "    training_test, test_removed = movie_avg(pd.concat([training, test_new]), test_removed)\n",
    "    \n",
    "    return training_validation, training_test, validation_removed, test_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d39ff1ce-2647-43a2-a457-24f225c47744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating training set user averages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:00<00:00, 5987.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:00<00:00, 1181.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating validation set user averages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:00<00:00, 564.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:00<00:00, 448.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating test set user averages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:00<00:00, 504.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:00<00:00, 425.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating validation set movie averages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1050/1050 [00:15<00:00, 65.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1050/1050 [00:04<00:00, 239.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating test set movie averages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1050/1050 [00:16<00:00, 65.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1050/1050 [00:04<00:00, 231.88it/s]\n"
     ]
    }
   ],
   "source": [
    "if (os.path.isfile('./' + path + '/training_validation.csv') and os.path.isfile('./' + path + '/training_test.csv') and os.path.isfile('./' + path + '/validation_removed.csv') and os.path.isfile('./' + path + '/test_removed.csv')):\n",
    "    print(\"Sets already exists\" )\n",
    "    training_validation = pd.read_csv('./' + path + '/training_validation.csv')\n",
    "    training_test = pd.read_csv('./' + path + '/training_test.csv')\n",
    "    validation_removed = pd.read_csv('./' + path + '/validation_removed.csv')\n",
    "    test_removed = pd.read_csv('./' + path + '/test_removed.csv')\n",
    "else:\n",
    "    \n",
    "    # training_validation has all training data as well as the unremoved values in the validation data\n",
    "    # this will be used to train, and we will use the removed validation data to predict\n",
    "    \n",
    "    # training_test has all training data as well as the unremoved values in the test data\n",
    "    # this will be used to train, and we will use the removed test data to predict\n",
    "    \n",
    "    training_validation, training_test, validation_removed, test_removed = add_avgs(training, validation_new, test_new, validation_removed, test_removed)\n",
    "    training_validation.to_csv('./' + path + '/training_validation.csv')\n",
    "    training_test.to_csv('./' + path + '/training_test.csv')\n",
    "    validation_removed.to_csv('./' + path + '/validation_removed.csv')\n",
    "    test_removed.to_csv('./' + path + '/test_removed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e7c027-a164-4969-8e62-4f9d2e629575",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ec3088d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for global avg: 1.007699663575643\n"
     ]
    }
   ],
   "source": [
    "# 1. Predicting average global rating for every movie\n",
    "global_avg = np.mean(training_validation[\"rating\"])\n",
    "ratings_pred = validation_removed.copy(deep=True).assign(rating = global_avg)\n",
    "    \n",
    "global_rmse = mean_squared_error(validation_removed[\"rating\"], ratings_pred[\"rating\"], squared = False)\n",
    "print(\"RMSE for global avg:\", global_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc12c93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 550/550 [00:03<00:00, 177.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for movie avg: 0.9279114110631916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Predicting average movie rating for each movie\n",
    "ratings_pred = validation_removed.copy(deep=True)\n",
    "\n",
    "for movie in tqdm(validation_removed.movieId.unique()):\n",
    "    if movie in training_validation.movieId.unique():\n",
    "        ratings_pred.loc[ratings_pred.movieId == movie, [\"rating\"]] = training_validation.loc[training_validation.movieId == movie, \"movieAvg\"].iat[0]\n",
    "    \n",
    "avg_movie_rmse = mean_squared_error(validation_removed[\"rating\"], ratings_pred[\"rating\"], squared = False)\n",
    "print(\"RMSE for movie avg:\", avg_movie_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac66850f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:00<00:00, 291.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for user avg: 0.970671907398001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Predicting average user rating for each movie\n",
    "ratings_pred = validation_removed.copy(deep=True)\n",
    "\n",
    "for user in tqdm(validation_removed.userId.unique()):\n",
    "    ratings_pred.loc[ratings_pred.userId == user, [\"rating\"]] = training_validation.loc[training_validation.userId == user, \"userAvg\"].iat[0]\n",
    "    \n",
    "avg_user_rmse = mean_squared_error(validation_removed[\"rating\"], ratings_pred[\"rating\"], squared = False)\n",
    "print(\"RMSE for user avg:\", avg_user_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db677965-9e59-4823-b768-a20fd814af5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for range avg: 1.426215589976112\n"
     ]
    }
   ],
   "source": [
    "# 4. Predicting average of the range 0.5 - 5.0, which is 2.75 for every movie\n",
    "range_avg = 2.75\n",
    "ratings_pred = validation_removed.copy(deep=True).assign(rating = range_avg)\n",
    "    \n",
    "range_rmse = mean_squared_error(validation_removed[\"rating\"], ratings_pred[\"rating\"], squared = False)\n",
    "print(\"RMSE for range avg:\", range_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d325f42-d16d-44e5-a042-772940f32419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for mode: 1.0287072646596973\n"
     ]
    }
   ],
   "source": [
    "# 5. Predicting class with mode class\n",
    "#print(training.rating.mode())\n",
    "mode = 4.0\n",
    "ratings_pred = validation_removed.copy(deep=True).assign(rating = mode)\n",
    "    \n",
    "mode_rmse = mean_squared_error(validation_removed[\"rating\"], ratings_pred[\"rating\"], squared = False)\n",
    "print(\"RMSE for mode:\", mode_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c043e981-c746-4cd5-8ba3-12c7e175e9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lowest baseline RMSE is 0.9279114110631916\n"
     ]
    }
   ],
   "source": [
    "print(\"The lowest baseline RMSE is\", min(global_rmse, avg_movie_rmse, avg_user_rmse, range_rmse, mode_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aeee06d2-e545-4e54-92a4-ffda1d4a8fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The lowest baseline RMSE is 0.9279114110631916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce780d9d-8c72-45da-a52d-f235b34d4502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_validation = training_validation.astype({'userId': str, 'movieId': str})\n",
    "#training_test = training_test.astype({'userId': str, 'movieId': str})\n",
    "#validation_removed = validation_removed.astype({'userId': str, 'movieId': str})\n",
    "#test_removed = test_removed.astype({'userId': str, 'movieId': str})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5a74f8-0006-4a23-824a-c1b59653086e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b463305-12b8-4580-8798-df1cb0d9bcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time building model: 0:00:02.976089\n",
      "RMSE for XGBoost validation set: 0.9147754471789399\n"
     ]
    }
   ],
   "source": [
    "#clf = HistGradientBoostingRegressor(learning_rate = 0.1, max_iter = 25, l2_regularization = 1, random_state = 1)\n",
    "clf = XGBRegressor(eta=0.255, max_depth=5, min_child_weight = 4, n_estimators = 200, subsample = 0.70, n_jobs=-1, random_state=1)\n",
    "#clf = AdaBoostRegressor(base_estimator = clf1, learning_rate = 0.01, n_estimators = 50, random_state = 1)\n",
    "\n",
    "use_cols = ['userId', 'movieId', 'userAvg', 'movieAvg', 'timestamp']\n",
    "use_cols.extend(genres)\n",
    "\n",
    "x_train = training_validation[use_cols].to_numpy()\n",
    "y_train = training_validation[['rating']]\n",
    "x_val = validation_removed[use_cols].to_numpy()\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "clf.fit(x_train, np.ravel(y_train))\n",
    "print('Time building model: {}'.format(datetime.datetime.now()-start))\n",
    "\n",
    "ratings_pred = clf.predict(x_val)\n",
    "xgb_val_rmse = mean_squared_error(validation_removed[\"rating\"], ratings_pred, squared = False)\n",
    "print(\"RMSE for XGBoost validation set:\", xgb_val_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a82409b5-d738-4067-86b4-74a070627daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time building model: 0:00:02.446730\n",
    "#RMSE for XGBoost validation set: 0.9147754471789399"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20bf9de7-4f60-4e91-bacd-e9aa23fc7428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time building model: 0:00:03.254929\n",
      "RMSE for XGBoost test set: 0.8594862008237355\n"
     ]
    }
   ],
   "source": [
    "x_train = training_test[use_cols].to_numpy()\n",
    "y_train = training_test[['rating']]\n",
    "x_test = test_removed[use_cols].to_numpy()\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "clf.fit(x_train, np.ravel(y_train))\n",
    "print('Time building model: {}'.format(datetime.datetime.now()-start))\n",
    "\n",
    "ratings_pred = clf.predict(x_test)\n",
    "\n",
    "xgb_test_rmse = mean_squared_error(test_removed[\"rating\"], ratings_pred, squared = False)\n",
    "print(\"RMSE for XGBoost test set:\", xgb_test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73a002f5-4786-450f-9d69-1798c0660ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time building model: 0:00:03.062357\n",
    "#RMSE for XGBoost test set: 0.8594862008237355"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c301270-71ea-4f56-b4e1-5293a8b62164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 461/461 [00:01<00:00, 261.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE for user avg: 0.9830622358141182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Baseline on test set\n",
    "ratings_pred = test_removed.copy(deep=True)\n",
    "for user in tqdm(training_test[\"userId\"].unique()):\n",
    "    ratings_pred.loc[ratings_pred[\"userId\"] == user, [\"rating\"]] = training_test.loc[training_test.userId == user, \"userAvg\"].iat[0]\n",
    "\n",
    "avg_user_rmse = mean_squared_error(test_removed[\"rating\"], ratings_pred[\"rating\"], squared = False)\n",
    "print(\"Baseline RMSE for user avg:\", avg_user_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae8fbeef-0424-40ef-a466-f6d663d8184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline RMSE for user avg: 0.9830622358141182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "838cf655-0473-4919-8238-10613a4a7565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 620/620 [00:03<00:00, 164.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE for movie avg: 1.0358683519569263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Baseline on test set\n",
    "ratings_pred = test_removed.copy(deep=True)\n",
    "\n",
    "for movie in tqdm(test_removed.movieId.unique()):\n",
    "    if movie in training_test.movieId.unique():\n",
    "        ratings_pred.loc[ratings_pred.movieId == movie, [\"rating\"]] = training_test.loc[training_test.movieId == movie, \"movieAvg\"].iat[0]\n",
    "    \n",
    "avg_movie_rmse = mean_squared_error(test_removed[\"rating\"], ratings_pred[\"rating\"], squared = False)\n",
    "print(\"Baseline RMSE for movie avg:\", avg_movie_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb55fa71-7c7e-461f-9540-5cf0ab95a41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline RMSE for movie avg: 1.0358683519569263"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
